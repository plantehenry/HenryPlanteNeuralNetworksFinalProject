{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMYf5vCv7zbGcT2ooCgSWlo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/plantehenry/NeuralNetworksFinalProject/blob/main/DataFormatter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "data_path = \"/content/gdrive/My Drive/Neural Networks Project/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMcxo9PCGig0",
        "outputId": "0e36f823-c36c-4e4d-d0be-e056854ff5d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ouKIULfDC6xp"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "import csv\n",
        "import numpy as np\n",
        "\n",
        "first_day = datetime.datetime.strptime('1/31/2013', '%m/%d/%Y')\n",
        "last_day = datetime.datetime.strptime('12/31/2022', '%m/%d/%Y')\n",
        "\n",
        "def get_trading_days(file_name):\n",
        "  first_day = datetime.datetime.strptime('1/31/2013', '%m/%d/%Y')\n",
        "  days = []\n",
        "  with open(file_name + '.csv', newline='') as csvfile:\n",
        "    spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
        "    spamreader.__next__()\n",
        "    for row in spamreader:\n",
        "        cur_date = datetime.datetime.strptime(row[0], '%m/%d/%Y')\n",
        "        if first_day <= cur_date and cur_date <= last_day:\n",
        "          days.append(cur_date)\n",
        "\n",
        "    return days"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trading_days = get_trading_days(data_path + \"SandPPrices\")"
      ],
      "metadata": {
        "id": "6W18ZNYHFZh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_values(date_line, line_wanted, date_format, fine_name):\n",
        "  data = []\n",
        "  with open(data_path + fine_name + '.csv', newline='') as csvfile:\n",
        "      spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
        "      spamreader.__next__()\n",
        "      for row in spamreader:\n",
        "          try:\n",
        "            if row[date_line] != '':\n",
        "              cur_date = datetime.datetime.strptime(row[date_line], date_format)\n",
        "              data.append([cur_date, row[line_wanted]])\n",
        "          except:\n",
        "            print(row)\n",
        "\n",
        "  # check to make sure you have every day\n",
        "  value_data = np.zeros(len(trading_days))\n",
        "  data_idx = 0\n",
        "  for days_idx in range(len(trading_days)):\n",
        "    # if current date we are looking for is between the current and the next available piece of data\n",
        "    # take the current data\n",
        "    if data_idx + 1 < len(data) and trading_days[days_idx] >= data[data_idx][0] and trading_days[days_idx] < data[data_idx + 1][0]:\n",
        "      value_data[days_idx] = data[data_idx][1]\n",
        "    # if it is not the iterate through the data until it is\n",
        "    else:\n",
        "      while(data_idx + 1 < len(data) and trading_days[days_idx] >= data[data_idx + 1][0]):\n",
        "        data_idx += 1\n",
        "      value_data[days_idx] = data[data_idx][1]\n",
        "      \n",
        "\n",
        "  return(value_data)"
      ],
      "metadata": {
        "id": "ixsJgmt-J-IC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SandPData = get_values(0, 1, '%m/%d/%Y', \"SandPPrices\")\n",
        "RealEstateData = get_values(0, 1, '%m/%d/%Y', \"RealEstateIndexDailySince2013\")\n",
        "BondData = get_values(0, 1, '%m/%d/%Y', \"isharesBondIndexSince2003\")\n",
        "FederalFundsRateData = get_values(0, 1, '%m/%d/%Y', \"fed-funds-rate-historical-chart\")\n",
        "EuroData = get_values(0, 1, '%m/%d/%Y', \"USD_EURHistoricalData\")\n",
        "JPYData = get_values(0, 1, '%m/%d/%Y', \"USD_JPYHistoricalData\")\n",
        "SavingsData = get_values(2, 1, '%m/%d/%Y', \"PersonalSavingsRates\")\n",
        "CPIData = get_values(4, 3, '%m/%d/%Y', \"CPI\")\n",
        "ExportData = get_values(4, 3, '%m/%d/%Y', \"ExportPriceIndex\")\n",
        "ImportData = get_values(4, 3, '%m/%d/%Y', \"ImportPriceIndex\")\n",
        "UndemploymentData = get_values(4, 3, '%m/%d/%Y', \"UnemploymentRate\")\n",
        "print(len(SandPData))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gqp5Gy1TN0OW",
        "outputId": "c3ef001b-88a4-481e-b04c-27bce3f933d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2498\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# full_data = np.column_stack((SandPData, RealEstateData, BondData, FederalFundsRateData, EuroData, JPYData, SavingsData, CPIData, ExportData, ImportData, UndemploymentData))\n",
        "full_data = SandPData\n",
        "\n",
        "input_data = []\n",
        "# not acatually how you should get truth values but just for now\n",
        "\n",
        "def normalize(arr):\n",
        "  ret_array = []\n",
        "  for val in arr:\n",
        "    ret_array.append((val - min(arr))/ (max(arr) - min(arr)))\n",
        "  return ret_array\n",
        "\n",
        "\n",
        "\n",
        "sequence_length = 63\n",
        "prediction_length = 21\n",
        "\n",
        "output_data = []\n",
        "data_idx = 0\n",
        "while data_idx < len(full_data) - sequence_length - prediction_length:\n",
        "  # input_data.append(full_data[data_idx: data_idx + sequence_length])\n",
        "  # need to dobmy percent\n",
        "  # output_data.append(list(nn.functional.normalize(torch.Tensor([(full_data[data_idx + sequence_length + prediction_length][0] - full_data[data_idx + prediction_length][0]) /full_data[data_idx + prediction_length][0], (full_data[data_idx + sequence_length + prediction_length][1] - full_data[data_idx + sequence_length][1])  / full_data[data_idx + sequence_length][1], (full_data[data_idx + sequence_length + prediction_length][2] - full_data[data_idx + sequence_length][2]) / full_data[data_idx + sequence_length][2], .000575]), dim = 0).numpy()))\n",
        "  \n",
        "  \n",
        "  \n",
        "  # output_data.append(normalize([(full_data[data_idx + prediction_length][0] - full_data[data_idx][0]) /full_data[data_idx][0], (full_data[data_idx + prediction_length][1] - full_data[data_idx][1])  / full_data[data_idx][1], (full_data[data_idx + prediction_length][2] - full_data[data_idx][2]) / full_data[data_idx][2], .000575]))\n",
        "  output_data.append([(full_data[data_idx + prediction_length] - full_data[data_idx]) /full_data[data_idx]])\n",
        "  # output_data.append(normalize([(full_data[data_idx + sequence_length + prediction_length][0] - full_data[data_idx + prediction_length][0]) /full_data[data_idx + prediction_length][0], (full_data[data_idx + sequence_length + prediction_length][1] - full_data[data_idx + sequence_length][1])  / full_data[data_idx + sequence_length][1], (full_data[data_idx + sequence_length + prediction_length][2] - full_data[data_idx + sequence_length][2]) / full_data[data_idx + sequence_length][2], .000575]))\n",
        "  # values_dummy.append([(full_data[data_idx + 63 + 30][0] - full_data[data_idx + 63][0]) /full_data[data_idx + 63][0], (full_data[data_idx + 63 + 30][1] - full_data[data_idx + 63][1])  / full_data[data_idx + 63][1], (full_data[data_idx + 63 + 30][2] - full_data[data_idx + 63][2]) / full_data[data_idx + 63][2]])\n",
        "\n",
        "  data_idx += 1\n",
        "\n",
        "print(output_data)\n",
        "\n",
        "print(len(output_data))\n",
        "print(len(input_data))\n",
        "# print(output_data)\n",
        "\n",
        "\n",
        "with open('/content/gdrive/My Drive/Neural Networks Project/output_data.csv', 'w', newline='') as file:\n",
        "     writer = csv.writer(file)\n",
        "     for data in output_data:\n",
        "       writer.writerow(data)\n",
        "with open('/content/gdrive/My Drive/Neural Networks Project/input_data.csv', 'w', newline='') as file:\n",
        "     writer = csv.writer(file)\n",
        "     for idx in range(len(output_data)):\n",
        "       # input data is just done by dataloader now\n",
        "        # writer.writerow(full_data[idx])\n",
        "        writer.writerow([full_data[idx]])\n",
        "  \n",
        "# for idx in range(len(values)):\n",
        "#   print(values[idx])\n",
        "  # print(values_dummy[idx])\n",
        "\n"
      ],
      "metadata": {
        "id": "fPHi7HZKN7bB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba272d58-a931-43bc-f423-c0404a1f07fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.010812538283309815], [0.018082784308228465], [0.017592207088430175], [0.03058748019335299], [0.021815799747235822], [0.025811443536227417], [0.031025778625802428], [0.02276126040067721], [0.024726270756290327], [0.02881343661767898], [0.026553445633513854], [0.020192193929195728], [0.018785490100605977], [0.018139182463061898], [0.022454446244915535], [0.036254842187936814], [0.02381235154394309], [0.051013206976509795], [0.04403650112896966], [0.03508598341677719], [0.0313531571024903], [0.03428402055065206], [0.018679517440335698], [0.013112177634612547], [0.0076550802485954575], [0.01220649372514985], [0.011256164780968836], [0.020247779876881155], [0.026293414407915036], [0.02207755448627225], [-0.006940846079541543], [0.008887037867623432], [-4.510018684359019e-05], [-0.004346590542129001], [-0.002219784308819496], [0.010738081376544348], [0.014060081315956728], [0.017555052877829984], [0.013691446842526031], [0.012464328218778405], [0.015549522680635659], [0.02264798325406318], [0.007973252666772795], [0.0282617510571606], [0.03488506262900811], [0.04139036606878434], [0.0402019051762193], [0.040851454472431104], [0.02453817714598832], [0.02435197389066714], [0.02826590468517918], [0.06233734443041576], [0.053030351143486795], [0.06470235755752149], [0.08050025622563434], [0.07133901302041476], [0.06840960000000007], [0.04613689051039405], [0.0429024719271912], [0.04256352671023747], [0.04691153607947724], [0.03486489539276357], [0.034164814872774035], [0.030920474863688378], [0.026996745117676586], [0.009074578790881976], [-0.005106488207474261], [-0.0004182170423445147], [0.0073375839871623015], [0.007346206099502699], [-0.0013234483181176733], [-0.01322111706197393], [-0.008252836344011768], [-0.01654333049871226], [-0.007673454567460476], [-0.008332783017452083], [-0.024954987396471104], [-0.04838294227232714], [-0.03805354742616335], [-0.04199384211772856], [-0.0365236017741419], [-0.030261323095311324], [-0.023054440496258783], [-0.025633576050310893], [-0.010675916676370233], [-0.017827430473021155], [-0.006384088886160562], [0.015478875777516844], [0.01084127560343827], [0.004189290252755795], [0.011454620905140836], [0.027804704467649075], [0.041832335700772154], [0.028847094502054433], [0.028988617965952007], [0.02517426224409519], [0.020776956466464568], [0.0429577378094571], [0.06798982764915476], [0.06753022778627489], [0.06826537856889298], [0.05968836943483201], [0.05221483528796586], [0.04766870251750347], [0.04844140193069862], [0.0465405844055282], [0.05871621118474935], [0.05520649924319643], [0.043807367519275435], [0.03190110110841252], [0.025303349560415585], [0.023343650635630184], [0.007825650943734047], [0.0065849403723528795], [0.006644083912759294], [0.001013165187644044], [-0.011796198804318687], [-0.01832577172849396], [-0.028092374336789877], [-0.02709488810170752], [-0.030087378984234033], [-0.01500703176458718], [-0.013643017584202062], [-0.022350797482133544], [-0.03416631119958296], [-0.0321491207280656], [-0.029909673142261825], [-0.04111716780962421], [-0.03939672484353134], [-0.03078339068701305], [-0.022332330560962604], [-0.021554905955650044], [-0.012841223984434864], [-0.004341465437078322], [-0.0008517434122970777], [-0.005218787635487841], [0.007198099558826243], [0.02197782352728717], [0.030502945174444955], [0.04890060176948159], [0.04348563604861084], [0.04037008443615015], [0.025712082510000383], [0.020266900600255978], [0.02511890786304718], [0.04003680417113938], [0.032910927456381994], [0.026554558268096076], [0.03420031174546902], [0.03146789214491192], [0.01542993322365237], [0.017925234095955228], [0.011690859160455152], [-0.010350470638826466], [-0.011992576024365783], [0.0011129462885016556], [0.008795043441105217], [0.01032689011053971], [0.0016257001996783887], [0.0084596714622393], [0.005430314819317627], [0.013213812963005963], [0.020473986818118056], [0.029173029484318148], [0.029128043250373988], [0.03657507157403857], [0.03768755308106073], [0.04484785984377042], [0.05341147520521151], [0.04216561262485957], [0.039205838035867364], [0.05039939480220881], [0.04654002311590551], [0.05296440801326793], [0.06864857361842859], [0.05267689417658095], [0.0466385585628205], [0.04097396256162278], [0.03229637777400716], [0.04837429211580191], [0.04097850793816891], [0.0357570592841678], [0.02612308044923213], [0.02468393568778337], [0.017834009598977327], [0.02845812255362008], [0.02865587325812492], [0.024695638335360412], [0.023001480489866274], [0.02054991620915553], [0.024562736780018572], [0.02354011485756517], [0.016870817738459793], [0.015376599251275642], [0.013235127478753484], [0.020031173407727858], [0.033877268541555865], [0.018531492237112677], [0.006894564031850651], [0.007713801526890691], [-0.0029561071378488187], [-0.002339919359342396], [-0.00965077106102884], [0.01016869649707673], [0.011622773931459263], [0.02209114559971298], [0.017143238686630913], [0.015849817032325273], [0.02224231364435602], [0.021064830217135764], [0.01875390475979844], [0.02175970773020395], [0.018393422587634094], [0.021838663803920393], [0.02001874142412518], [0.02770135766847849], [0.01815403524507115], [0.017957512724054017], [0.021356142803257226], [0.02225390215018149], [0.03517474887231575], [0.039668519477012394], [0.03233191713266945], [0.03345009149798475], [0.019740187949143194], [0.01762051270720666], [0.002216224518903717], [-0.020235008369711496], [-0.02831669355190306], [-0.028660260340645772], [-0.03491775592325694], [-0.028074307639706607], [-0.034227947948381694], [-0.04876146213472548], [-0.04307677194361207], [-0.04140623718358845], [-0.03367430219272], [-0.023273518216421943], [-0.021526471962870723], [-0.01148126826195111], [-0.003590723415469739], [-0.006552496033729568], [-0.004848511085016713], [-0.0028900950532200036], [-0.006414817631243012], [-0.0019732098812279978], [-0.0029908429183244717], [0.011330297324517255], [0.030574585573664312], [0.03471676948962428], [0.03629304806859749], [0.04530236274526353], [0.03258174752077186], [0.0512542912917629], [0.07475542200456477], [0.07137072397312612], [0.07123257976371793], [0.05757287402661021], [0.03894332479679326], [0.038107139881696186], [0.01370788739204011], [0.015423017158726491], [0.016658827647309776], [0.018063870627450355], [0.011523193213333964], [0.02475891627123831], [0.014448119843352038], [0.012358584043815833], [0.010516004026714782], [0.003424008148272521], [0.00280231990893807], [0.002177756694984794], [0.008763619137849345], [0.020213818724550154], [0.009274032176302719], [0.008574416544835574], [-0.007772075889530008], [-0.01724303196191403], [-0.013640284092724058], [0.0032848377675963247], [-0.02055043711812347], [-0.01457397280319981], [-0.006164498781751727], [-0.006944892733415145], [-0.005618907731339288], [0.0030643678531684197], [-0.0010455954292542858], [0.006237718654794403], [0.01209477918557877], [0.005693351686314055], [0.006959629827602087], [0.0111941710313664], [0.009649519137674986], [0.005565753804777083], [-0.0006943671453029219], [-0.006333832074144968], [-0.003470440417934107], [0.0024732821151121826], [0.017290894509829464], [0.012215001295448592], [0.004139338133185207], [0.036107393548739465], [0.043422543422543446], [0.030964536296377205], [0.013640229467879407], [0.008019422794927332], [0.010231590907872883], [0.000411199581324053], [0.004719792265287508], [0.006030914414151081], [0.012935900986302517], [0.02507774798927613], [0.021285239311944718], [0.023030206169090628], [0.020951077006352077], [0.020033946851959892], [0.02320359679693522], [0.023799032749550045], [0.03953910293118126], [0.038127400273784307], [0.04003156878742791], [0.03688239017462483], [0.02456834058257541], [0.01774786124303545], [0.024722481145665533], [0.03525029526664852], [0.03520616414267898], [0.038527651627689764], [0.04649983452016192], [0.03957758488287726], [0.03625905816238147], [0.024847398278663092], [0.025170391835838055], [0.024055270595624432], [0.02106929538152299], [0.01997016430424097], [0.0259948935816169], [0.027466641706447102], [0.028882251674859503], [0.017493732013323663], [0.008276166385321417], [0.00837289908426231], [0.00840784458568671], [0.013641392440888153], [0.024114356743318802], [0.021453970354137805], [0.021991069354463984], [0.009682251264972458], [0.009925925925925958], [0.00775332194139103], [0.011411570517392387], [0.01330295570268654], [0.018124733874732554], [0.009367872686732366], [0.011995543198266359], [0.006334181630873308], [0.0014523847137783593], [-0.02192533425237955], [-0.02493066380549437], [-0.02413038876737464], [-0.02990300497371477], [-0.021408579716044953], [-0.02863723959789907], [-0.016446565196158194], [-0.01732610439320555], [-0.021119067848039807], [-0.014643155311559101], [-0.010546786210380153], [-0.0016211751990783077], [-0.0021245061787721594], [0.0024346417634702223], [0.0007555457054782101], [0.0022785918000875083], [0.003597702307769878], [0.010281814735245757], [0.010358428912693238], [0.012269347915325806], [0.016950446278636608], [0.03848585345631671], [0.03994041378164872], [0.0337389094890361], [0.04209587490676947], [0.043753867594369354], [0.0473107022273406], [0.028436509209022316], [0.029508247534521803], [0.03158710477371363], [0.01983660348873626], [0.011772093094488238], [0.02090524724769708], [0.015379702240042944], [0.016299243610070374], [0.011203833261191246], [9.033423667573205e-05], [-0.00421741793607604], [-0.0006354479908335285], [-0.0171553680506263], [-0.00924192207948255], [-0.01012784908303936], [-0.016281866401872132], [-0.028818558872412747], [-0.026752661527624524], [-0.014009009009009013], [-0.022324965000473387], [-0.0325781089902186], [-0.010425415281556629], [-0.033730586847981435], [-0.045619359556076364], [-0.05484783790860207], [-0.05436619860439067], [-0.0717000950332616], [-0.06897412471855695], [-0.06315768554309058], [-0.049624703844545676], [-0.02583827617699897], [-0.026379743261367158], [-0.0228956802114834], [-0.0016529177813266063], [-0.007488781986497926], [0.0025679781216351788], [0.004083309661972951], [0.028455723264622357], [0.03597827649220795], [0.02324861295120327], [0.02697262479871179], [0.045351450492108175], [0.032871198568872904], [0.05524425772344629], [0.06955631936609553], [0.0855783624827528], [0.08805450917201121], [0.09902745224817476], [0.0929696339233528], [0.08265716316118843], [0.0742544700373942], [0.053871394794183215], [0.0654783482304689], [0.05814745925117481], [0.054600936336266], [0.05255226205871273], [0.046130419656227904], [0.04359203633259082], [0.026269238456925813], [0.02439785750739506], [0.028688219623873246], [0.02852691175959799], [0.025458032056066098], [0.011902418862800038], [0.013213517650011632], [-0.005043665979786072], [-0.0036265488897068337], [-0.016761392892345597], [-0.02599841156225792], [-0.03165398446737215], [-0.011021415835570272], [0.004816786598802682], [0.011442564776843255], [0.01167458905640935], [0.008803575665715851], [0.0068352534840470935], [0.009804775172200285], [0.0066079295154183], [0.007905004405115707], [0.002497845425729322], [-0.006292776125178246], [-0.02483073243185885], [-0.03243470122251287], [-0.02131730639471007], [0.0033551335975296665], [-0.006183033329123892], [0.001804804923271063], [-0.005890580980712686], [0.004349062108796391], [0.002788529780390678], [0.02380723184565578], [0.0005993125241458738], [-0.012974032527267792], [-0.0030445372303410756], [-0.014922074677633197], [-0.016987879515180656], [-0.024929232835964238], [-0.04080224944075342], [-0.03310525786573069], [-0.041035295925767636], [-0.01757734712710673], [-0.002716068612371219], [0.010533343223796432], [0.028286504948767294], [0.01125770088791048], [-0.006818677457655727], [0.010957270554656874], [0.018901544610598692], [0.03486920332936985], [0.04107759155803838], [0.05366294390764204], [0.03884182188879432], [0.03834292814042245], [0.03712825050385881], [0.022356009268146026], [0.03164229767559822], [0.03225318136982018], [0.038645108594034555], [0.051327124272765846], [0.04774308564637151], [0.0556176033095102], [0.0374893088974692], [0.025404371211307616], [0.01409381193569696], [0.006720716876466664], [-0.004275689442748005], [-0.004040246318398832], [-0.0019288873848832449], [-0.007067701137209108], [-0.003920949070749458], [-0.011271327517207332], [-0.00022389908344280568], [-0.004253900202453179], [0.004929325673968341], [-0.0027916941175354757], [-0.007586174197525011], [-0.02617122866732857], [-0.02749880553098271], [-0.0221566360948988], [-0.010060658455370594], [-0.02274832684236402], [-0.022626345055320254], [-0.016044488072660075], [-0.009576802433231262], [0.002263240439136231], [0.0024805648944676616], [0.02289833666717212], [0.029851550634461953], [0.013426589684969318], [0.02066314739582079], [0.01219365660702007], [0.014347465313289873], [-0.006947190866683468], [0.005979945654253894], [-0.0046110275665443385], [0.001554226831563629], [0.009411877120061285], [0.028811518782100403], [0.02557180243022099], [0.02343867332651828], [0.010302056092704013], [0.009551999148783873], [0.02436857715664326], [0.023129785410219636], [0.005031742751551216], [0.00145406222615963], [0.005208308308789331], [0.01149886923801451], [0.0003996137067499944], [0.0035081346664880848], [0.0012441486876851552], [0.007649717943360808], [0.00890334731615456], [0.021755089702558735], [0.011874530392520424], [0.013001186691893894], [0.010986090612705944], [0.005935251798561134], [-0.0066814829494782945], [0.006602319349254191], [0.003867473928870704], [0.0014818192180553454], [0.011032969559926676], [0.00019429161750134083], [-0.00013253622262308123], [0.0018314317684075278], [0.0059520375391834985], [-0.006242441913265401], [-0.016279377564332873], [0.0016025717234065305], [0.003719720711366793], [-0.004327685283489424], [-0.017817508376255235], [-0.011266676094847541], [-0.013087886543473617], [-0.003162906113855229], [-0.0061395874009080855], [-0.0033797104714697384], [-0.0007951668909445334], [0.0022943951204913364], [-0.009258953856012709], [-0.010388275348240522], [-0.022502655740192647], [-0.02056946280580544], [-0.015450289959443426], [-0.018178805595663643], [-0.012204726288608204], [-0.007016068134242184], [-0.014112078958380498], [-0.013636887829630252], [-0.012443975995138058], [-0.003658484504823428], [0.008449128310078739], [0.012613589475401322], [0.01401735482025369], [0.01202428648921287], [0.003059790859287449], [0.002702958579881674], [-0.00423896456225626], [-0.010081698961693456], [-0.015057157481658411], [-0.015157279964996], [-0.0018726502527840977], [0.022118290890213974], [0.021577164973391346], [0.012733213668714879], [0.011441934472865798], [0.01244249874367003], [0.011113464185670488], [0.016041137125377542], [0.013757222054424935], [0.010879650774267512], [-0.008867849046539488], [-0.010820242673102623], [-0.01298239795314022], [-0.017444047395147808], [-0.011688647530385373], [-0.014974971211017426], [-0.019639223684148364], [-0.037877927876792644], [-0.06521139356115367], [-0.0866667629042581], [-0.09561752988047809], [-0.07253067265002142], [-0.057300714834961526], [-0.05913525288880465], [-0.06386345385342761], [-0.08636207619846681], [-0.06895531363499693], [-0.07282637153397596], [-0.07457469233317816], [-0.05263385520283711], [-0.0766029695718756], [-0.06229878429676607], [-0.059021469760664226], [-0.06146940930801919], [-0.0534430779537732], [-0.05074239173354767], [-0.050594314998878634], [-0.05574951483427326], [-0.03573605757885621], [-0.01114927613668172], [0.019351133777290745], [0.033736483780536675], [-0.006995166694976718], [-0.05244554545179897], [-0.05012759660346394], [-0.025602891238471252], [0.002739340053847599], [0.0018146494497100988], [0.01995625744444907], [0.02855808644217297], [0.01144335387658827], [0.03715511513759347], [0.03289861385123884], [0.026458692042016063], [0.024837604214618267], [0.00932750932750935], [0.014553983551592951], [0.021144316114310956], [0.03686685298137543], [0.036749448095483264], [0.04046849591404052], [0.06376853541174592], [0.07187759888012472], [0.07234680019490143], [0.09808172591529833], [0.10662166029017445], [0.08874013492042815], [0.08273102400391319], [0.07588278335797956], [0.06240215842909842], [0.060201579950967], [0.052452094021594634], [0.041132624532583775], [0.030531094187979044], [0.03395037220843665], [0.03425231825758855], [0.024127585187856602], [-0.0011312161314384049], [0.010798678958326183], [0.009276337469812393], [0.024701618415811293], [0.03014026549547948], [0.015168667615720511], [0.004501031285540869], [0.009933534743202506], [0.010810653865510503], [0.0012450020350994369], [-0.0033827751196173032], [0.010068436532805232], [-0.010425039117676468], [-0.028124703875675224], [-0.005357618666971073], [-0.012012770418374173], [-0.016880032052504997], [-0.01408633779288365], [-0.01734656164653135], [-0.0284323140101048], [-0.009336606933249933], [0.012076673524291854], [0.009782486962365007], [-0.0054483696314308735], [-0.03524019772520029], [-0.02864865902958492], [-0.022594895209652396], [-0.010026770036748876], [-0.01509117886373436], [-0.013538744362846104], [-0.006509003084722099], [-0.010725276413513509], [-0.030218250852876938], [-0.03216690456622983], [-0.019271270061036128], [-0.050276977832206034], [-0.06145491200401268], [-0.0655210390215267], [-0.05864458257850617], [-0.05223053139058359], [-0.06044095223431353], [-0.0537483646417022], [-0.07712680185682869], [-0.09527621325515014], [-0.0878817724334945], [-0.06609559909862849], [-0.05776635444727287], [-0.08001664871217319], [-0.07802202062495155], [-0.08385290873129649], [-0.0808234734584138], [-0.06758643264944597], [-0.06082238582153662], [-0.06433617898145427], [-0.05070563815312492], [-0.049032912298492375], [-0.05644933814196197], [-0.05010868615651834], [-0.03583369675824974], [-0.0419279708273032], [-0.0551140521764226], [-0.010699484056500046], [-0.00932863075735131], [0.020601908231232646], [0.021618394823524366], [0.033833657451677726], [0.034611697027804415], [0.00591728392471199], [0.028252226166841386], [0.027558185984904265], [0.032839668579794444], [0.022750791974656768], [0.020475595526965137], [0.026012008722342175], [0.04558825842785008], [0.044170803538267495], [0.043809165372934694], [0.05775523822234088], [0.07709661015115285], [0.07409940229389916], [0.09327016783974011], [0.09919821097414633], [0.07630487752746545], [0.06746366125974307], [0.05892911800868459], [0.06841825182340855], [0.06453825528465414], [0.05465974732029781], [0.05993032812532598], [0.05487946911541678], [0.041330980331977775], [0.05707888019803499], [0.06539706466916874], [0.040483658808054226], [0.04411261079774383], [0.034347871876269434], [0.02477318384257383], [0.03311666199270868], [0.032350209948320365], [0.029764386203709744], [0.024569987617247616], [0.023102408296067436], [0.03355381661018121], [0.034186591468742505], [0.025620405545414098], [0.02689157145936629], [0.026192940992636225], [0.02609047953764462], [0.02096116765517053], [0.027990435330236887], [0.025492053054875407], [0.027793196610585744], [0.015867694714493168], [0.003900628461505004], [0.0051297760402992205], [0.001924570348110777], [-0.0010666666666665785], [0.003612702633997474], [-0.0073872642401152855], [0.005871310265260136], [0.006048101920272404], [0.01936175209911335], [0.0006050573110285006], [-0.009789283159456272], [-0.01755556622341699], [-0.006633539058027816], [-0.02465112950549847], [-0.027270737371045694], [-0.02864292204425121], [-0.01877130658047601], [-0.017574675619923614], [-0.005220495348926381], [-0.00042536311193734866], [-0.00041608279569373005], [0.013664314467473015], [0.012950071837342831], [0.009883592177856615], [0.021244478959374837], [0.023322535863026433], [0.030477055528697], [0.02680858302349875], [0.025705046469798258], [0.012614662384977703], [0.011890652437873966], [0.006860606060606104], [0.015181795527062851], [0.0006392127997521422], [0.016542912765728342], [0.01534578149994369], [0.021210844907634113], [0.018282551176037765], [0.019560080871069148], [0.01196769491998293], [-0.028683586428489467], [-0.039898376123173436], [-0.027350687814563884], [-0.009919099878697567], [0.0007770378174295346], [-0.004286929617360631], [-0.007806438407677009], [-0.004625197850420232], [-0.002716889681972555], [0.007595774348308893], [0.014187725460638819], [0.02966893749253015], [0.039115883755086324], [0.042130342703119085], [0.046303645057008375], [0.04118467904917725], [0.043611906069628725], [0.042068108901347025], [0.036712525421701066], [0.03866112385321094], [0.03097237868438683], [0.06810898619212873], [0.07942511723402458], [0.061751905575491074], [0.04822566407964615], [0.0336296169272247], [0.029479010047492784], [0.037938429210863586], [0.03255063273059668], [0.03644570164738958], [0.023699172499202517], [0.02024304744099086], [0.01121733114805849], [0.011983984280868108], [0.00967609335236213], [0.011193132411981194], [0.006493236404641939], [0.0072942154101842864], [0.005214205834572039], [0.006974479221960207], [0.006486605848986253], [0.007432099106949541], [0.0016038270631990904], [0.004178112231942812], [0.0006270662062034034], [0.0028990175551617363], [0.0016682488916743739], [0.006732164632025993], [0.006461721924095365], [0.0059111301693571825], [0.0006456753489393772], [0.00023828726446240405], [-0.00629005731144718], [-0.026221665128536974], [-0.015235330213303774], [-0.026632145209690313], [-0.027846896955503356], [-0.014399588583183395], [-0.01737476511297507], [-0.01753470314617429], [-0.016960184820176204], [-0.0077109072542862], [-0.00540023523058555], [-0.0067869451384766875], [-0.013360305273320742], [-0.0038429814901000123], [-0.004840670811443129], [-0.007844273910082872], [-0.003223830555466005], [-0.00648453035375588], [-0.012128657276048439], [-0.01233313655230498], [-0.008507577562352325], [-0.004006306821325196], [0.01909131201493723], [-0.005952187196287197], [0.0011278937524085658], [0.006737682086799275], [-0.006303343147851459], [-0.0026492660879947373], [-0.0023905607798913805], [-0.0009652239599360756], [-0.014514449961767813], [-0.011406669151378768], [-0.004086095231035869], [-0.004226389070101286], [-0.008229063070980857], [-0.01690718797547147], [-0.012395027150349415], [-0.016471610151871523], [-0.02493332162320826], [-0.02614667192538798], [-0.034486752972356774], [-0.029387438256345287], [-0.014103934937673198], [-0.013783052259004773], [0.013949767737770426], [0.015232882371165874], [0.012132655350332778], [0.016568602170702617], [0.01834158751537441], [0.017656868194748803], [0.020695352647128688], [0.02196846823686683], [0.024696299744007423], [0.022714586085629936], [0.03242909352962381], [0.030852681361529105], [0.03214005993724889], [0.035304115918075855], [0.03358419302102723], [0.03872610136387558], [0.04852773013150367], [0.05925261182748754], [0.05242812733565315], [0.0522132286658654], [0.05543827056240504], [0.04214090953130126], [0.046520337909382266], [0.04742708852810257], [0.03942277093931163], [0.04100058322962243], [0.037009836547156054], [0.03642225118320877], [0.03846910260104377], [0.02787568814840381], [0.028063951240590305], [0.0271770907459196], [0.027155790626230077], [0.02214689470910039], [0.021152215222883002], [0.02336183113123081], [0.03216619810872979], [0.030686388112602977], [0.028940858802315835], [0.02843869870449462], [0.012756957427726054], [0.008387673187449112], [0.005449723972144847], [0.004162027464079148], [0.00034827076950204495], [0.006819684351109426], [0.002245446243840527], [0.004744958481613399], [0.0005647474078977278], [-0.0011715274780448063], [0.01146743381368415], [0.016980422519632832], [0.014468963873922755], [0.006950837580333358], [0.010900200044454316], [0.015091423470316803], [0.011156659575318506], [0.011911920764060866], [0.011507023252123008], [0.010888804741231285], [0.007019735308476918], [0.011886928784167219], [0.0192497575597285], [0.022270753894519903], [0.023487068472416606], [0.02927981526040705], [0.03547599531099888], [0.031299793124697446], [0.0374235669351001], [0.041154785737593555], [0.04392648641021566], [0.029206424102617833], [0.02897378003419424], [0.029168950248366673], [0.04117217335007278], [0.05309100183815447], [0.04170914293464704], [0.04328213327242618], [0.035918096253506525], [0.0329210035392366], [0.029452887140822386], [0.036238562162870344], [0.03259459224104155], [0.02433971811250425], [0.020941371052495713], [0.02647756779529867], [0.02060730097020873], [0.012172077424626714], [0.015497159636535885], [-0.005057518121711596], [-0.006412238311641697], [-0.007214361140443475], [-0.011300106548713091], [-0.010755825014903436], [-0.004031985393562333], [-0.007907131123089984], [-0.012498173086960992], [-0.007803706130403342], [-0.00861811277223671], [-0.0017505082801149163], [-0.006760035614669523], [-0.0029194115481764836], [-0.006474128774467709], [-0.007438141982492483], [-0.006924067467437922], [-0.011964528295518839], [-0.023072316152296612], [-0.017275591410028837], [-0.01322406485468238], [-0.015395154918211971], [0.005010670081092523], [0.010383764498267296], [0.013227423183941656], [0.025705097655327525], [0.02133097414725247], [0.015760394476647913], [0.01151479475375959], [0.011091753283548014], [0.010227147658677351], [0.01487625065824107], [0.010893310628372361], [0.019606676891311497], [0.019091144407809495], [0.016812604999236418], [0.017383768352365447], [0.0171290096294879], [0.022203434700552523], [0.03083657003712576], [0.017254848390415325], [0.003366300350691835], [0.012242336800857064], [0.013789208150369152], [0.011268473166183627], [0.008356043014725797], [0.008606183392075256], [0.010377871699376567], [0.007515624477791617], [0.01135859325936785], [0.010288367035402817], [0.01876388015922908], [0.020102184710790474], [0.01653172377182467], [0.013371167612523707], [0.013611872184145462], [0.016522098306484885], [0.012961199913146582], [0.017434084031365482], [0.020789647365475058], [0.008147054542429847], [0.02026479783461674], [0.03731276728571495], [0.03343636800667967], [0.021824640479890713], [0.016837432833828443], [0.013841867902607318], [0.014019273388281664], [0.009045351004348787], [0.007061496805118339], [0.011073715759449916], [0.0056092563078259374], [4.52436576616731e-05], [-0.002891916171348998], [-0.0034869568077897373], [-0.0076109258520660585], [-0.004009415553738806], [-0.003710407611260908], [0.004068626642702809], [0.004453299919889773], [0.00221381074168792], [0.014586616284538076], [0.010134746055510903], [0.008720394669505117], [0.010160528184244282], [0.011515551528916024], [0.014211865102157984], [0.017756145647218294], [0.015000081855835352], [0.019053169918812674], [0.01664264833038254], [0.013740695551060828], [0.019718425819199775], [0.020148968285630953], [0.018615423855717093], [0.02205129897996239], [0.026359839570419923], [0.022206548952159275], [0.015654932333614847], [0.012164631017140557], [-0.0016155485298507636], [0.0023681588789626574], [0.003724334214271134], [0.005191621740475919], [-0.0003652819773931412], [-0.019357236342484156], [-0.016981437950879506], [-0.015489231565832253], [-0.013317836214828805], [-0.012927575736803247], [-0.015321658154634526], [-0.008816906428201134], [-0.017771028377101223], [-0.012530781962779042], [-0.007148098275264281], [-0.0006502344478863855], [-0.0026363812538355512], [-0.005373131918260553], [-0.004151955938426761], [-0.001257427951406457], [0.003707339233708342], [0.020851768098843152], [0.01585769218235728], [0.010491521716234756], [0.01095344381296507], [0.01606203942426781], [0.032397719595986266], [0.0335353535353536], [0.030163328197226443], [0.021424364385982178], [0.021030184933269615], [0.023037403056382803], [0.022861462398104184], [0.02938806056070454], [0.026123643737275493], [0.02377520151056777], [0.022599235376371058], [0.02555508328779327], [0.031264332360593144], [0.032162913381360306], [0.03620266016854498], [0.03049884422029315], [0.023547918489209143], [0.023653809911423615], [0.024493297415175384], [0.02400157072048792], [0.02184207056115654], [0.022575200794800254], [0.018569194683346255], [0.024091003366358787], [0.0323634703635183], [0.02771476240202609], [0.02618110865879795], [0.022682059681220685], [0.026703576321897078], [0.027008398540215764], [0.021731715056322373], [0.020894425255104012], [0.018148949271357982], [0.016163818549624814], [0.015713814653141877], [0.015959927725671206], [0.01518437327205215], [0.013087014137739102], [0.010693804644166482], [0.008166187990577911], [0.008679081379105185], [0.004802183663972182], [0.003933090636669019], [0.011572850210896175], [0.00464643474738656], [0.0043016508409359465], [0.012321599588890743], [0.013208546981905494], [0.01663229274085182], [0.013881864091570438], [0.019423916205993663], [0.02249232333976454], [0.02395856318301643], [0.03013421413784281], [0.022405719752278477], [0.01498374860384854], [0.013992461739663817], [0.022211835238400594], [0.02638931888544894], [0.0316063220395477], [0.0353421074080255], [0.03418485112986127], [0.03548619354336543], [0.043906799588021635], [0.04249808357917721], [0.04213623623274371], [0.03624713711343786], [0.032269229438028485], [0.030252805316064356], [0.030522619166545018], [0.030760493334458912], [0.023338737052005055], [0.01890710838936501], [0.019942535253865638], [0.023378079851271414], [0.03468092037972851], [0.044333343487267085], [0.04670937992223346], [0.03754048242580904], [0.03799878590900341], [0.040744177658890955], [0.04924669833070295], [0.04468334915055869], [0.05328437249824289], [0.04344135342824799], [0.043246394895848354], [0.05463547827898443], [0.06052880709051744], [0.060360179120936434], [0.0628534315756469], [0.06902427202565159], [0.05459215963664788], [0.05327333915921379], [0.049453559039098496], [0.041169820412550795], [0.007998352523250384], [-0.04267151900356227], [-0.018857536634010016], [-0.024040855642185947], [-0.05236473566316402], [-0.04221622465918619], [-0.04472994534651173], [-0.05278746391516849], [-0.02568411376701523], [-0.026855552383671218], [-0.027328195247270284], [-0.03155035669025604], [-0.04396042397841311], [-0.04555390768322423], [-0.031223649446286996], [-0.023540112661019637], [-0.03956780586140624], [-0.04148633478540212], [-0.06126231724926829], [-0.04807115340233268], [-0.028032126226450106], [-0.011265714723501167], [0.045116606368413324], [0.02302532562849553], [0.039303391793698995], [0.07323063441182565], [0.052075471698113183], [0.040812162024283234], [0.03747722737919672], [0.010289445947240818], [-0.004433215749833045], [-0.0040425383619284], [-0.010722175458458489], [-0.023505582160698354], [-0.03551439723101858], [-0.03256726518385263], [-0.06083547627182637], [-0.05061043365846231], [-0.030115423427935852], [-0.02509317798028493], [-0.03618717969758229], [-0.026672234065153108], [-0.023747500166040512], [-0.0422907327783369], [-0.041592351366372314], [-0.05255255255255258], [-0.04959334744351452], [-0.035024476759695125], [-0.030559821658733558], [-0.021024733055330487], [-0.011406663797065704], [-0.0051159278834645135], [-0.008261540558160375], [-0.005930087390761562], [0.012880141760903213], [0.00594422280336731], [-0.005967978347334867], [0.02457396698962188], [0.02319452572473343], [0.003869448821887659], [0.02394518878005675], [0.017043079828485613], [-0.01351341180720727], [0.008897052709556947], [0.020281371552587284], [0.015050731311661205], [0.02312123424196926], [0.025951172456412014], [0.021095296798535543], [0.01816036852552348], [0.007382814530923933], [0.003542291641298659], [0.0059937212160701536], [0.012400837864337239], [0.023525454137699055], [0.012376902417188838], [0.03644133408224917], [0.02713404861124199], [0.01107842734173821], [0.010235322704248389], [0.029255117943441676], [0.024285671227922134], [0.04322166752914681], [0.04845028514753294], [0.03142700872119155], [0.03916472553234514], [0.03275432019476359], [0.027785376817916266], [0.02310206780034528], [0.019964366331671222], [0.023769674721086993], [0.024021057132956446], [0.016942982891558264], [0.012755073877123047], [0.016060455987820833], [0.011298816071050363], [0.017247732112985338], [0.004394091411748335], [-0.0005433984432368991], [0.008628114938024586], [-0.0013839396395095458], [0.002260215069570556], [-0.005057564277044175], [-0.0030638260622175865], [-0.008830399569213299], [-0.005655134840642936], [-0.0022812126104567927], [0.008214502646573843], [-0.0001294880187612574], [-0.0008831131533601509], [0.003224603111975072], [0.006546397864336431], [0.004161596670722643], [0.016472689538974378], [0.020842947518359186], [0.012571622504720735], [0.010793419228102565], [0.021693066115133667], [0.027266363828592665], [0.04164768636210009], [0.04174531327310381], [0.044580889246263904], [0.030288251751841647], [0.04296567404203414], [0.024589594149132737], [0.03870141216288138], [0.03748064054235708], [0.031572939956872055], [0.024467825687810203], [0.027832737371484444], [0.020300811313839765], [0.013775818486697988], [0.009441606608053842], [0.013841984125276829], [0.0071460330446227426], [0.010304801432349698], [0.01760710274375556], [0.022270887441634538], [0.014290880213281886], [0.01510435705337273], [0.009472789535494793], [0.014896124685559536], [0.029247960269599083], [0.03234830392955902], [0.03111120563454169], [0.03495472204764893], [0.02379824852807096], [0.018061535969918628], [0.01145690355472135], [0.00401499585198781], [0.008469860247305856], [0.01124438309081443], [0.018631897469899038], [0.024389295161039295], [0.027733870825156135], [0.025566496199813476], [0.01846867160855704], [0.018455252931921972], [0.02034590128987835], [0.026483839510099805], [0.021515300896062975], [0.02075217915349279], [0.011193577126138325], [0.0035154836374916934], [0.00324413401272842], [0.005964371901792374], [0.008773897052481322], [0.01198842924997239], [0.009600254531243973], [0.004811953029799522], [0.0032319245814535578], [0.00038870128653196745], [0.0008114028214530473], [-0.038576458735099343], [-0.04360253378669933], [-0.049047268423261986], [-0.047103308389265124], [-0.02735285774576742], [-0.035987063923484455], [-0.049343603689382294], [-0.055442051784960346], [-0.06872405307632536], [-0.06293488491486271], [-0.08299679805826571], [-0.08372915700719522], [-0.07813665151218376], [-0.09760139972456597], [-0.07462890758601828], [-0.07303296051083168], [-0.059568054532687105], [-0.06069511531279503], [-0.0483504950426234], [-0.03759917571838436], [-0.023494206479000655], [0.006204827737704689], [0.0012235881813653197], [-0.012222169959802067], [-0.010534684953289637], [-0.04202128983842346], [-0.02978586723768738], [-0.01618353832962253], [-0.04302183897272477], [-0.023259574499362525], [-0.03817200962792235], [-0.009312567292738482], [-0.0015405605991319362], [0.0032803384712876173], [0.03646409258221366], [0.01188645771732714], [0.02683269673753857], [0.013469558724434982], [-0.023056298301404314], [-0.017214431784983886], [-0.051645020240579924], [-0.0505776124402255], [-0.04862746501556848], [-0.041540341681296944], [-0.036764894415853316], [-0.0537455714233537], [-0.049607947964002454], [-0.06308165412316898], [-0.08568007206837701], [-0.07128004219091381], [-0.0967664256097285], [-0.10262174560257627], [-0.07829145235606434], [-0.0619352416705772], [-0.07152650058518634], [-0.09499921445978574], [-0.08979603763660808], [-0.11330227557785345], [-0.08870663412916038], [-0.03581739884588385], [-0.04134123050169817], [-0.021798955474635635], [-0.02864767080512225], [-0.029312738175402458], [-0.027682702072441386], [-0.005677496881749809], [0.007152369005114427], [0.03569280050001949], [0.04351308376356959], [0.05875991781381546], [0.07035832204366062], [0.1070083647148999], [0.11927028673956461], [0.08286182190378705], [0.06197048948082453], [0.07465165230057533], [0.09098249467088694], [0.08610629554720846], [0.10265809330202529], [0.07865562921742698], [0.05818286599873061], [0.043550387596899276], [0.05396909279544274], [0.05196842483511133], [0.06587968112358601], [0.06127422536845774], [0.05564203078688203], [0.0613195977434388], [0.04819577032893677], [0.046036690896503855], [0.05189749875164558], [0.06272074093162137], [0.05077066650611117], [0.05388718964676356], [0.05414969998752321], [0.0544916001537522], [0.04799124182179048], [0.03407812546256538], [0.030955222446785398], [0.013997522302938803], [-0.0015575583627356786], [0.011068875044617696], [0.035277600320908056], [0.03221501253502437], [0.032237448624665294], [0.021993964294804123], [0.028835429196282167], [0.029171376402052154], [0.022410157152761706], [0.014634497400190575], [0.0231203061606193], [0.005516656057712762], [0.0029632535168577197], [0.0097981635605723], [0.007856502242152499], [0.01440402279680495], [0.018015023836581937], [0.019141051105575988], [0.029229783746837542], [0.030004264820250297], [0.04251896780443359], [0.05773787072605366], [0.05057850277149952], [0.03373467176591293], [0.032909728621534504], [0.03219493449284439], [0.03469842997876049], [0.031761383967321054], [0.026499950717413557], [0.025948844010256555], [0.028038244932121065], [0.023016185507572385], [0.049352470127073854], [0.041359424886050905], [0.037624303122295887], [0.04669324410906237], [0.03849349602407121], [0.036403464121349496], [0.018798984743257217], [0.01846951938221679], [0.012143396462757384], [0.010009846887828812], [-0.0030639164122057807], [-0.009263557566393374], [-0.006340733748182282], [-0.01788777006279566], [-0.027833125349034503], [-0.030237387907795583], [-0.01938700528112189], [-0.01969794653022594], [-0.021643412133667914], [-0.015440978618591344], [-0.01853270973439766], [-0.0331629175187458], [-0.03297382374128964], [-0.032736233726728584], [-0.05112256765672076], [-0.051138182041033056], [-0.06306205607096763], [-0.05839173761874766], [-0.05686516159647146], [-0.031214655762163483], [-0.029014462604229952], [-0.009285979698639828], [0.009087921002573494], [0.014030246935140258], [0.014977871198757816], [0.02344581081656096], [0.023557109325693718], [0.011888087401078442], [0.01682991674246139], [0.027660682491537514], [0.03348960413732207], [0.033840325483358226], [0.04044135791588827], [0.0400259849386213], [0.03393603601375249], [0.04637935668846872], [0.05238720603959898], [0.0742042188601485], [0.07745872296504114], [0.0779833782179365], [0.058961921017426644], [0.05347691894318908], [0.03948655213872349], [0.03585450286399416], [0.03318671704664048], [0.04184575038245001], [0.045581794999722966], [0.043407624999133976], [0.039916947832857486], [0.024825317971176986], [0.02866240947766689], [0.010960808245185763], [0.014234381297181147], [0.016043125004235218], [0.02392575141388699], [0.029794229119604054], [0.035898015522355324], [0.02547614339195476], [0.015080382713930406], [0.0052822246058571], [-0.011477193359479878], [-0.028878277624193628], [-0.039798373699983604], [-0.03603752461625614], [-0.031141069815675958], [-0.02303958501410168], [-0.03206075861701559], [-0.04542381867585671], [-0.03916829618907551], [-0.052876776147216434], [-0.03831318587249531], [-0.03021709172974383], [-0.021100428246135765], [-0.024275897072867703], [-0.022619273902299918], [-0.034874314548480584], [-0.04863519455737167], [-0.0434224839393348], [-0.04866906498739873], [-0.03509359396860969], [-0.01450515380898696], [-0.011851625394884293], [0.009178522257916443], [0.03474790121558241], [0.04256554667412934], [0.031841613695139444], [0.013820120047363769], [0.025572139645760057], [0.044558304868227434], [0.040792633415683344], [0.052775630665448686], [0.045703973135432986], [0.030211293710614106], [0.03129485681789371], [0.029561539198642083], [0.017932813363630763], [0.03138364931107794], [0.03545889001290686], [0.032003290542455654], [0.043403651512609595], [0.019482058982191363], [0.015866044281925274], [0.005421088274017614], [-0.013433994262600554], [-0.01419982435992703], [-0.012112752614643315], [-0.022764461606930644], [-0.020164859761495353], [-0.021083983752653836], [-0.015290387759713855], [-0.015403972498597405], [-0.007609105562990288], [-0.0019995526877126775], [-0.0002432117274696046], [-0.004491157203789574], [-0.003968860730882009], [0.009126864420982074], [-0.002804395106630169], [0.01564168645880718], [0.00589135655266891], [0.01562568037863388], [0.02302608297074208], [0.018785463637308073], [0.041753567789714056], [0.05730267763691427], [0.05495860972534404], [0.046385642426033345], [0.052972195589645193], [0.060430765002919884], [0.05574686059858485], [0.039573820395738125], [0.041631122694980545], [0.03718375980710305], [0.033806293650156596], [0.03570750174121978], [0.04039922051227283], [0.04370795066211014], [0.03451986727471405], [0.038236345235987707], [0.03205209003642045], [0.03799794893651022], [0.03388058520111342], [0.03627211000892799], [0.03534512820175412], [0.03181922609865759], [0.012026669114176344], [0.007970223711902709], [0.012467540898467883], [0.019355468114858047], [0.017764705120148282], [0.01756105476673432], [0.017991578824346766], [0.016816216076237768], [0.026739684454214818], [0.030050958505217214], [0.028147442662616803], [0.02479224865374568], [0.020742138163679785], [0.03488984351421988], [0.03781900536916651], [0.036652193057167], [0.035208376103469434], [0.03584860519642092], [0.030074805515198068], [0.02160664467872826], [0.03206896003308051], [0.04500536048014364], [0.03674883196391177], [0.03932085367769406], [0.03316829472152932], [0.039521175354726205], [0.04670914982649514], [0.043173084589013824], [0.04588011702422296], [0.03651177111458478], [0.037485511821411306], [0.040138949740251534], [0.03937769348493531], [0.04313477345629505], [0.02867841642028587], [0.033182994683901276], [0.006730843758235297], [0.008722731779871125], [0.013004930356026527], [0.005049242459314301], [0.020885300356434194], [-0.002776861745570495], [0.01681461461213256], [0.03336700284377855], [0.0317903919354938], [0.02993586715206303], [0.015998015939841334], [0.025613914272916455], [0.03037788164946055], [0.024517935684173736], [0.029190164124218893], [0.02000320923290256], [0.017068532882424804], [0.017892039517860305], [0.009153098179590518], [-0.017540420475485288], [-0.028249977498424846], [-0.033031941758336444], [-0.059228654368961846], [-0.1132587111562384], [-0.08664957238710855], [-0.05662745671519923], [-0.05869281692143175], [-0.06246094476332155], [-0.11149474722624073], [-0.14380911950061592], [-0.1565143874754912], [-0.14847451089118466], [-0.2183714760225439], [-0.23750482124313907], [-0.2547045366766689], [-0.28194122104864305], [-0.27679695106024266], [-0.2919515203867009], [-0.28058690411039944], [-0.3183425085552745], [-0.2803190068792765], [-0.24118075666730476], [-0.20338545813560946], [-0.1654411044427175], [-0.1227056121224588], [-0.12089984803044775], [-0.1932464814659321], [-0.1927965197406222], [-0.18232597457489344], [-0.1272493399228216], [-0.04373072988138504], [-0.04566586576055277], [-0.0172034258210646], [0.057623742806534706], [0.09148284623675584], [0.11442682941413293], [0.154052917556459], [0.1666037348655858], [0.1889048581981048], [0.14509815209256802], [0.21704187784573334], [0.19875961850164645], [0.1443869849497715], [0.14127110411027916], [0.13853991008932384], [0.14047784664202143], [0.12093976723818112], [0.14851806187151742], [0.14499255655795726], [0.1407440395718353], [0.11824161844330315], [0.050977671480474], [0.08336312849162009], [0.049863341243576775], [0.056439265973275435], [0.02166054686107455], [-0.00039346983159487957], [0.010934720326934088], [0.025129906453281274], [0.0361854358628349], [0.06062173002826052], [0.06530386779966209], [0.0489713281288918], [0.0680641674725525], [0.05639920830924982], [0.046959408376747475], [0.03656380419810449], [0.036804268981306267], [0.06820629537588575], [0.10084866483600408], [0.08459050221689295], [0.0973591292826572], [0.11175501865710527], [0.10467782579250084], [0.10219999588401145], [0.06260588535465222], [0.07159456498223912], [0.07128901357647421], [0.10637997137758624], [0.07628026054786434], [0.05190616531969508], [0.06319681205838235], [0.04190979646121997], [0.0646698665219381], [0.03672338952358132], [0.010263127352312044], [0.008727733447996195], [-0.002175084375423506], [0.0037580871270706064], [0.013423475747035634], [0.014437381006163406], [0.014054043630847555], [0.0008217861838777906], [-0.01464099102477559], [-0.011561251291499163], [-0.01896733075663943], [0.02610828133554015], [0.022816374908825727], [0.07756800812356361], [0.024707761098690554], [0.028085570432348123], [0.03954359629099447], [0.04083380834254162], [0.05184816540741077], [0.042355115175072504], [0.03345106601592597], [0.056863388695595166], [0.05241116751269041], [0.06911505040432774], [0.059523965641597405], [0.052973032145064824], [0.046003995368426524], [0.042668027344554736], [0.0476655171106984], [0.05394742267060354], [0.051596734431721254], [0.06457476201200969], [0.051561895490908255], [0.06824020807930951], [0.045558248966205556], [0.04996322108491557], [0.0485855449862137], [0.05047622887519423], [0.037934600369586305], [0.03244993640279455], [0.03495800271423517], [0.061986963194949396], [0.06711824190021853], [0.06669202014674094], [0.07992017897757206], [0.08135814540683708], [0.07316424345273592], [0.06665531314433767], [0.07715689135298127], [0.07456810666280816], [0.039248669192367476], [0.009529797458121863], [0.004106029725509886], [0.012526926066806256], [-0.0008225399796153786], [-0.0027839131917164125], [0.01159808351095099], [0.008982921505179124], [-0.011862865510888516], [-0.010355164760015478], [-0.022291458363090943], [-0.026656743482742287], [-0.028665131696356743], [-0.06106317030224536], [-0.061829523155273805], [-0.04339567420534033], [-0.04113955744286331], [-0.04801508947981753], [-0.034660607166480444], [-0.057797367767568955], [-0.055395344400994126], [-0.012989344452165893], [0.003760513422778935], [0.019128618145776342], [0.013804885481867023], [0.043940704506815455], [0.05067547479456298], [0.03161635458208244], [0.01245591766019875], [0.043814201968412146], [0.04059117526166229], [0.04681379486664412], [0.043741181825077705], [0.03565845709931294], [0.07400794757822048], [0.06326274616425581], [0.02077146885029545], [-0.00251871127929048], [-0.019166709066475905], [-0.02725444272816137], [-0.012800469610115855], [-0.009212210485051683], [-0.0006688688489001055], [0.029894580093128748], [0.021564927728665088], [0.03565947041191787], [0.012354215118770818], [0.008265398230338788], [0.01342636973150113], [0.028621312671554256], [0.030530986117074527], [0.033389053313716874], [0.05021544580709315], [0.03473928096956025], [0.04095099607386941], [0.029414990331611324], [0.04448744994798656], [0.0682749805327417], [0.0885779421268041], [0.10893850486852978], [0.10695927544108397], [0.10848249499423591], [0.09952191832146877], [0.07764071793005056], [0.059955705244797444], [0.049798480192911755], [0.03431164597660089], [0.03270152345580056], [0.026060697908071948], [0.03160550935113269], [0.03204440728824476], [0.02669048042309235], [0.028623580800540716], [0.030536337688152764], [0.035081656791434636], [0.033182373138956944], [0.03549380120106983], [0.027683807573751214], [0.024076468161188337], [0.030633081859531966], [0.02806960579828193], [0.023972330335420653], [0.030332970239040098], [0.008107341860490416], [0.011239627997188667], [0.01894049091543902], [0.03583986098478163], [0.02621708697834307], [0.038940950444504505], [0.03997450821645043], [0.03801353369956494], [0.03336233536347549], [0.0231667230300981], [0.02761972722254378], [0.036285827116449426], [0.04341689556711205], [0.04153506684549818], [0.04590325497777127], [0.03865696813507192], [0.0087885405167296], [0.007477313393830939], [-0.0013436147519264227], [0.01568865900403672], [0.020097699363280618], [0.037490332664506916], [0.04474435644631226], [0.03396808784740395], [0.025016710134860513], [0.03093233486014197], [0.030192391664606195], [0.028777848788737154], [0.03266858541853433], [0.03425158298427177], [0.03542682475382614], [0.02749841466162854], [0.007281993850876003], [0.003337460720454598], [0.005719582104432404], [0.01367862985896829], [0.0007375880609774026], [0.023100579112028282], [0.033242016384113414], [0.03559741314386632], [0.0070387991054475015], [-0.012157999307340383], [0.002014773266330615], [-0.006799370858365868], [-0.0001541390179804099], [0.0012913982646676457], [0.000953891827646484], [0.006781738331120403], [0.015834750041542583], [0.0025281690319600256], [0.008931989281612863], [-0.0006946111454444884], [-0.0011935243652388162], [0.013395786954227773], [0.016297344875773494], [0.0014533870630481138], [0.00033709586802178583], [0.03376601053218256], [0.03144559155343771], [0.016295047699070645], [0.03333083160153117], [0.056542700987029], [0.0743334791937959], [0.05980142493347452], [0.061792400173419554], [0.052446177919264925], [0.05342047329359426], [0.052383476195815126], [0.050373323594456926], [0.041818607355061814], [0.05685935430945651], [0.05724041988111804], [0.06287533796388589], [0.05411491951956861], [0.05913754571312478], [0.0558300785983423], [0.0787994865105919], [0.06921666938975576], [0.05437468980754851], [0.06126146129274808], [0.058188921797214785], [0.04989005154303502], [0.035841405498656546], [0.02490203824250356], [0.023280129789484884], [0.029435567671976512], [0.032269641196159354], [0.006213770180206635], [0.00010895619960771362], [-0.016078404859981008], [-0.0024590797534157272], [-0.0010109866942652269], [-0.003315948131489684], [-0.014601435859953276], [-0.0015623410408824243], [-0.00044359615006506805], [0.007581944437732886], [0.004996379954265526], [0.0007974691100101821], [0.004014202631214075], [0.0011007717289486581], [0.004387699197255918], [0.0035400932256356536], [0.0029647957425629635], [0.006940288145250434], [0.014439428755090933], [0.005574371665946278], [0.0011115604653417382], [0.018846648708298656], [0.027199767585430377], [0.04253261971195037], [0.030438930835581298], [0.018933216944209918], [0.013065478619471308], [0.025943954421793588], [0.012477043743646698], [0.013433734506226296], [0.01897049513687738], [0.01213284069672907], [0.019768154805217035], [0.01974326144590357], [0.01957836690201545], [0.017580848661929552], [0.02232327506287406], [0.0322491369294012], [0.035760392767560975], [0.02876808201752521], [0.02061027774038025], [0.022771138131675323], [0.03401867302344047], [0.032564990926017605], [0.031024101348536066], [0.02672914590814252], [0.027903889740095698], [0.018015008162791356], [0.014347956373460664], [0.037794124694493815], [0.03234854815000693], [0.03104768583780258], [0.03584944220889498], [0.03320427189462979], [0.027550234544563512], [0.02571036590336837], [0.02434829221679705], [0.024677205962708684], [0.015286830305551568], [0.013655582743787337], [0.013295763512379759], [0.024993809403689365], [0.025035917383089572], [0.014495438442415078], [0.013948647248275098], [0.015061265584654326], [0.02193169177527219], [0.021573328021284678], [0.0385718275765758], [0.04122519700546995], [0.011846792869297271], [0.011301753846929899], [0.0157696521500959], [0.016967602356686966], [0.016771654613054063], [0.02062253716258422], [0.016011935716086244], [0.026993574691931126], [0.02788606853859672], [0.0309738340989907], [0.026841336518755816], [0.028025385246980037], [0.024002781622327128], [0.018099180444232057], [0.01741065289384765], [0.014573925414998893], [0.0064618720310926645], [0.00324535705646782], [-0.0031737137606042284], [0.003354907532742341], [0.0064851135120042565], [0.004680041255556316], [-0.008187168976275253], [-0.018619011345327983], [-0.017315582909642236], [-0.011671436047612123], [-0.011489290681502111], [-0.012194631322500702], [-0.03353080358725328], [-0.035118935923616076], [-0.04673202614379092], [-0.040939644678110704], [-0.04910180433410853], [-0.04758366443385127], [-0.02973823009280483], [-0.02360060447327958], [-0.026954106130128885], [-0.023799893179822156], [-0.02708440771276055], [-0.01365714144382557], [-0.006566765465961271], [-0.0013468344914915693], [0.021437899590047656], [0.03428316702671199], [0.03773615146665189], [0.03162648210132181], [0.02605880073185452], [0.03074432928421558], [0.03635672490802217], [0.04594478739962551], [0.046262929939803236], [0.06797524298381344], [0.06082081658557224], [0.07442915911616818], [0.07948939362019845], [0.07197751686349312], [0.0669395961883666], [0.07338146229340738], [0.06912284155657446], [0.06915541726613755], [0.061204764347181806], [0.054322580935272154], [0.04832292348086345], [0.04539572280503583], [0.038966320544953865], [0.03887702328208564], [0.0364882581190114], [0.02740414916254729], [0.021204755071865568], [0.01842924575675401], [0.014444950951600286], [0.014734728955776157], [-0.0016917464462480496], [-0.023542596036711057], [-0.008888600952350072], [-0.024568243572174662], [-0.014319275800870767], [-0.0022588631664922304], [-0.0034521217271230547], [0.0037214202207157864], [0.0109263229736081], [-0.0026314432768235366], [-0.011268206342097999], [0.008486094430506352], [-0.010422205679038605], [-0.024000578634762463], [-0.024101400888616946], [-0.013081494057725027], [0.00544621330004627], [0.012449259802642563], [0.028053671995420786], [0.034542803132595265], [0.033183556920424455], [0.03745312656154278], [0.060693981659278314], [0.04685052151764149], [0.052682609374347274], [0.013260016796309145], [0.0014496275736219334], [-0.007601790662971617], [-0.00394654879640928], [0.0038829798526633045], [0.019506826420044115], [0.0003299931413189686], [-0.01841229209621272], [-0.013857066093498174], [-0.00883846640074964], [-0.02689468461096504], [-0.06322951341401525], [-0.07170979345062452], [-0.06877074096058494], [-0.08652087690726075], [-0.09448402886832184], [-0.07559920988354744], [-0.05353481836400919], [-0.04431640763979289], [-0.05600987405583511], [-0.06374282318885374], [-0.03997963092775165], [-0.046329449129992255], [-0.023272199237864503], [-0.024822558329799606], [-0.04701612954390203], [-0.06780309111958034], [-0.045000097024788764], [-0.0381003574944303], [-0.028763979311381867], [-0.035796672787447775], [-0.031006087606063524], [-0.007205623094722018], [-0.04829113460234869], [-0.024963535771238325], [-0.0060288820201890745], [0.00621513356195202], [-0.02464692595993934], [-0.026166206077126657], [-0.04911319444900686], [-0.04594953929192722], [-0.06249010103083127], [-0.06273095489097257], [-0.05077432690032639], [-0.05882999780074775], [-0.07697595558327693], [-0.0704462892813792], [-0.02820779538640382], [-0.01900308853809199], [-0.010864613140324268], [0.0014227815603917442], [0.01927897148409095], [0.03701122153648744], [0.033538115067758154], [0.08834463889965022], [0.056465459079932445], [0.05711536297388471], [0.05983305601012103], [0.06395746964761623], [0.031583778465956565], [0.047407717888957555], [0.0567227716136546], [0.06936321282235541], [0.05956524827733164], [0.056812971040904735], [0.042794719009230126], [0.055877699125572576], [0.049054387631839155], [0.03754075193440502], [0.009325425593368278], [-0.0037914025239713833], [0.002209573323772092], [0.004490837081291469], [-0.023874385168369372], [-0.048018111937860895], [-0.0541178135315537], [-0.07808037277393746], [-0.08261819825065281], [-0.08011115436183552], [-0.10184995933916371], [-0.08381347570215315], [-0.08064916875001372], [-0.06605211648022385], [-0.08143884187736557], [-0.08791302113014418], [-0.102126097259771], [-0.10589247620242734], [-0.12025446244470542], [-0.09794506519809755], [-0.0980193836084439], [-0.07607344896856326], [-0.0771301612752612], [-0.12818127747492322], [-0.12505875250881562], [-0.1063447511645458], [-0.07341364027316268], [-0.0814723220838963], [-0.04823098898369063], [-0.034417346740618276], [-0.024133999412283245], [0.004640961020285157], [-0.015474376048733321], [-0.01043006998024495], [-0.03177900117786734], [-0.007678947330172889], [0.016134683566634875], [0.016472623278267588], [-0.003932251984922622], [-0.016854724061527358], [-0.050551224803854815], [-0.062040557983762804], [-0.07991609081934851], [-0.09528181284211668], [-0.047112080020518095], [-0.04935892213373534], [-0.036921279168856624], [-0.030735948302535683], [-0.002247053763878656], [-0.017969181348190512], [-0.061845606720215794], [-0.08795280275782996], [-0.08884808351286089], [-0.0739364312730593], [-0.07385736072138954], [-0.06672035833139858], [-0.05082668736741634], [-0.0641843013947028], [-0.06087793936586492], [-0.048993682049320725], [-0.019321808683871216], [0.014475809880112241], [0.031811479656221296], [0.03555354086980784], [0.07349354865108161], [0.06464063564009459], [0.0708483645742108], [0.05060256284588743], [0.03440047098842148], [0.007822462991868825], [0.02891132123690266], [0.06855786399797123], [0.08620994772833535], [0.08545970992414868], [0.08314854414242431], [0.08425670280116293], [0.06660533578656853], [0.06884056107359077], [0.06497652630548259], [0.08542945780708489], [0.11845743146888474], [0.12248438492132038], [0.11822158198009426], [0.1047095749255238], [0.10870224024990083], [0.08584054155697629], [0.07858484579582214], [0.049181803858014295], [0.042204189907507426], [0.04384527043776982], [0.051077711107118284], [0.04287243581305116], [-0.01290573552906176], [-0.017296553334079076], [-0.025227753940466], [-0.04168248960554631], [-0.0381385609588795], [-0.04494311044809482], [-0.05931283731920423], [-0.04189823159799754], [-0.03780895570937244], [-0.03399962151677144], [-0.04447316225722021], [-0.07697622834282339], [-0.08345259016515716], [-0.09332071768993548], [-0.09904215411185717], [-0.09166703779144046], [-0.07715705064027381], [-0.084859027991164], [-0.09679029697931693], [-0.11329413520945002], [-0.12201279431448477], [-0.0948401072726281], [-0.08765604701515614], [-0.0917821264938123]]\n",
            "2414\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get data points"
      ],
      "metadata": {
        "id": "igxqTwoRPC2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataloader import default_collate\n",
        "import sys\n",
        "import os\n",
        "from collections import Counter\n",
        "import string\n",
        "import numpy as np\n",
        "import argparse"
      ],
      "metadata": {
        "id": "MYVi2qWQSlS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LoadData(torch.utils.data.Dataset):\n",
        "    def __init__(self,args):\n",
        "        self.args = args\n",
        "        self.intput_sequence , self.output_sequence = self.loadData()\n",
        "\n",
        "    def loadData(self):\n",
        "        # Read the text\n",
        "        input_sequence = []\n",
        "        with open(f\"{self.args.workingDir}/{self.args.inputFile}.csv\", newline='') as csvfile:\n",
        "          spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
        "          spamreader.__next__()\n",
        "          for row in spamreader:\n",
        "              new_row = []\n",
        "              for val in row:\n",
        "                new_row.append(float(val))\n",
        "              input_sequence.append(new_row)\n",
        "\n",
        "        output_sequence = []\n",
        "        with open(f\"{self.args.workingDir}/{self.args.outputFile}.csv\", newline='') as csvfile:\n",
        "          spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
        "          spamreader.__next__()\n",
        "          for row in spamreader:\n",
        "            new_row = []\n",
        "            for val in row:\n",
        "              new_row.append(float(val))\n",
        "            output_sequence.append(new_row)\n",
        "        \n",
        "        return input_sequence, output_sequence\n",
        "\n",
        "    def __len__(self):\n",
        "        # Get the number of sequences for training purpose.\n",
        "        return len(self.intput_sequence) - self.args.seqLength\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return (\n",
        "            torch.tensor(self.intput_sequence[index:index+self.args.seqLength]),\n",
        "            torch.tensor(self.output_sequence[index:index+self.args.seqLength]),\n",
        "        )"
      ],
      "metadata": {
        "id": "qURRKFPeSl_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, dataset, args):\n",
        "        super(Model, self).__init__()\n",
        "\n",
        "        # Define input dimension of RNN.\n",
        "        self.inputSize = 1\n",
        "        \n",
        "        # Define embedding dimension of the RNN, i.e., output size of a RNN layer.\n",
        "        self.embeddingDim = 200\n",
        "\n",
        "        # Define the number of layers of the RNN.\n",
        "        self.numLayers = 6\n",
        "\n",
        "        # Define output of fc layer\n",
        "        fc_output = 1\n",
        "\n",
        "        # Define the embedding function.\n",
        "  \n",
        "  \n",
        "\n",
        "\n",
        "        #######################################################################\n",
        "        # *** Build your RNN units for both models: peephole LSTM and GRU.\n",
        "        # Look at the Pytorch documentation:\n",
        "        # -- LSTM: https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
        "        # -- GRU: https://pytorch.org/docs/stable/generated/torch.nn.GRU.html\n",
        "        #\n",
        "        # Define (using variables defined above in this class):\n",
        "        # -- \"input_size\"\n",
        "        # -- \"hidden_size\"\n",
        "        # -- \"num_layers\"\n",
        "        # -- \"dropout\" rate that comes in \"args.dropoutRate\"        \n",
        "        if args.rnnType == \"LSTM\":\n",
        "            self.rnnUnit = nn.LSTM(input_size=self.inputSize,\n",
        "                hidden_size=self.embeddingDim, num_layers=self.numLayers,\n",
        "                dropout=args.dropoutRate,batch_first=True)\n",
        "        else: # GRU\n",
        "            self.rnnUnit = nn.GRU(input_size=self.inputSize, \n",
        "                hidden_size=self.inputSize, num_layers=self.numLayers,\n",
        "                dropout=args.dropoutRate)\n",
        "        #######################################################################\n",
        "\n",
        "        # Fully-connected layer generating our output.\n",
        "        self.fc = nn.Linear(self.embeddingDim, fc_output)\n",
        "\n",
        "    def forward(self, X, prevState):\n",
        "        \n",
        "        # Calculate embeddings.\n",
        "        \n",
        "\n",
        "        # Get the output from the RNN cell (either LSTM or GRU).\n",
        "        output, state = self.rnnUnit(X, prevState)\n",
        "\n",
        "        # And pass it through the FC layer to get the RNN's output for a given time step.\n",
        "        output = self.fc(output)\n",
        "        # output = nn.functional.normalize(output, dim = 2)\n",
        "\n",
        "\n",
        "        # outmap_min, _ = torch.min(output, dim=2, keepdim=True)\n",
        "        # outmap_max, _ = torch.max(output, dim=2, keepdim=True)\n",
        "        # output = (output - outmap_min) / (outmap_max - outmap_min)\n",
        "\n",
        "\n",
        "        return output, state\n",
        "\n",
        "    def initState(self, seqLength):\n",
        "\n",
        "        # Define state initialization for LSTM and GRU.\n",
        "        if args.rnnType == \"LSTM\":\n",
        "            stateHidden = torch.zeros(self.numLayers, args.batchSize, self.embeddingDim)\n",
        "            stateCurrent = torch.zeros(self.numLayers, args.batchSize, self.embeddingDim)\n",
        "            return (stateHidden, stateCurrent)\n",
        "        # GRU has fewer gates compared to LSTM, we assign 0 as dummy for current state.\n",
        "        else: \n",
        "            weight = next(self.parameters()).data\n",
        "            stateHidden = weight.new(self.numLayers, seqLength, self.embeddingDim).zero_()\n",
        "            return (stateHidden, 0)"
      ],
      "metadata": {
        "id": "JEy_BTJ4TNQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model and generating texts\n",
        "from torchsummary import summary\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # Parsing arguments. The args has been treated as input for class \"LoadData\" and class \"Model\". \n",
        "    # To run it in the jupyter notebook, please modify the value in default.\n",
        "    # \"Wonder Land\" does not require GPU, CPU is feasible.\n",
        "    # If you are interested in \"Game of Thrones\", or other larger text files, you need GPU.\n",
        "    # If you ran out of GPU time in Google Colab, you may want to switch to a different Google account\n",
        "    # or use CRC resources.\n",
        "    #  \n",
        "    # The steps of running Practical 4 on CRC GPU clusters: \n",
        "    #    1. Fill in your scripts for each task. \n",
        "    #    2. Copy each piece of scripts in this file and create a '.py' file. \n",
        "    #    3. Follow instructions of Practical 1 how to run '.py' code on CRC machines.\n",
        "    #    4. Submit your notebook via Canvas.\n",
        "\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('-f')\n",
        "    parser.add_argument('--workingDir', type=str, \n",
        "        default=\"/content/gdrive/My Drive/Neural Networks Project/\")\n",
        "    # Can be game_of_thrones or wonder_land:\n",
        "    parser.add_argument('--inputFile', type=str, default=\"input_data\") \n",
        "    parser.add_argument('--outputFile', type=str, default=\"output_data\") \n",
        "    parser.add_argument('--maxEpochs', type=int, default=50)\n",
        "    parser.add_argument('--batchSize', type=int, default=12)\n",
        "    parser.add_argument('--seqLength', type=int, default=63)\n",
        "    parser.add_argument('--learningRate', type=float, default=.1)\n",
        "    parser.add_argument('--dropoutRate', type=float, default=0)\n",
        "    # Here define which RNN model, i.e., LSTM or GRU you like to train:\n",
        "    parser.add_argument('--rnnType', type=str, default=\"LSTM\") \n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # Create folder for saving your checkpoints.\n",
        "    try:\n",
        "        os.mkdir(f\"{args.workingDir}/checkpoints\") \n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    # If using GPU, we need the following line. Also, please make sure to send \n",
        "    # both models, hidden states, current states, and data to GPU, if you are \n",
        "    # using GPU (to train on \"Game of Thrones\" or other larger texts, you really need GPU).\n",
        "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "    print(\"currently using: \", device)\n",
        "\n",
        "    dataset = LoadData(args)\n",
        "    model = Model(dataset, args)\n",
        "    model.to(device) # if you're using GPU\n",
        "    # summary(model(), input_size=(128, 63, 11))\n",
        "\n",
        "    def train(dataset, model, args):\n",
        "\n",
        "        # Switch the model to training mode.\n",
        "        model.train()\n",
        "        \n",
        "        # If you are using GPU:\n",
        "        dataloader = DataLoader(dataset, batch_size=args.batchSize, shuffle=True, \n",
        "                    collate_fn=lambda x: tuple(x_.to(device) for x_ in default_collate(x)))\n",
        "        \n",
        "        # If you are using CPU:\n",
        "        # dataloader = DataLoader(dataset, batch_size=args.batchSize, shuffle=True,\n",
        "        #            collate_fn=lambda x: tuple(x_ for x_ in default_collate(x)))\n",
        "        \n",
        "        # Define the loss function and the optimizer. Do these names ring a bell? \n",
        "        # We used exactly the same losses and optimizers in CNNs and MLPs.\n",
        "        # criterion = nn.CrossEntropyLoss()\n",
        "        criterion = nn.MSELoss()\n",
        "        optimizer = optim.Adam(model.parameters(), lr=args.learningRate)\n",
        "\n",
        "        # Training loop starts here.\n",
        "        for epoch in range(1, args.maxEpochs+1):\n",
        "            stateHidden, stateCurrent = model.initState(args.seqLength)\n",
        "            stateHidden = stateHidden.to(device)\n",
        "\n",
        "            #######################################################################\n",
        "            # *** Task 3 *** The line below is only for LSTM\n",
        "            # Comments this line out for GRU (GRU does not pass the \"stateCurrent\" to the next step)\n",
        "            stateCurrent = stateCurrent.to(device)\n",
        "            #######################################################################\n",
        "\n",
        "\n",
        "            bestLoss = float('inf')\n",
        "            for batch, (X, y) in enumerate(dataloader): \n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                if X.shape[0] != 12:\n",
        "                  break\n",
        "\n",
        "                #######################################################################\n",
        "                # *** Task 1 *** Implement states update in our RNN models.\n",
        "                # Hint: GRU takes only the hidden state, while LSTM both hidden and current states.\n",
        "                if args.rnnType == \"LSTM\":\n",
        "                    # y_pred, (???,???) = model(X, (???,???))\n",
        "                    y_pred, (stateHidden, stateCurrent) = model(X, (stateHidden, stateCurrent))\n",
        "                   # print(y_pred)\n",
        "                else: # i.e., GRU\n",
        "                    # y_pred, ??? = model(X, ???)\n",
        "                    y_pred, stateHidden = model(X, stateHidden)\n",
        "                #######################################################################\n",
        "\n",
        "                # loss = criterion(y_pred.transpose(1, 2), y)\n",
        "                # print(y_pred.transpose(1, 2)[-1])\n",
        "                # print(y_pred.transpose(0, 1)[-1].size())\n",
        "                \n",
        "                # if epoch > -1 and epoch % 1 == 0 and batch == 0:\n",
        "                  # print(len(y_pred))\n",
        "                  # print(len(y_pred[0]))\n",
        "                  # print(len(y_pred[0][0]))\n",
        "                  # print(len(y_pred.transpose(0, 1)))\n",
        "                  # print(len(y_pred.transpose(0, 1)[0]))\n",
        "                  # print(len(y_pred.transpose(0, 1)[0][0]))\n",
        "                  \n",
        "                #  and (batch == 10 or batch == 12 or batch == 13):\n",
        "                  # print(\"y_pred \")\n",
        "                  # # print(y_pred.transpose(0, 1)[-1][-1])\n",
        "                  # print(y_pred.transpose(0, 1)[-1])\n",
        "                  \n",
        "                  # # print(\"y_actual\")\n",
        "                  # # print(y.transpose(0,1)[-1][-1])\n",
        "                  # print(\"y_actual\")\n",
        "                  # print(y.transpose(0,1)[-1])\n",
        "\n",
        "                # loss = criterion(y_pred.transpose(0, 1)[-1], y.transpose(0,1)[-1])\n",
        "                # loss = criterion(y_pred.transpose(0, 1), y.transpose(0,1))\n",
        "                loss = criterion(y_pred, y)\n",
        "\n",
        "                # Update states for the RNN models. Note the difference between LSTM and GRU!\n",
        "                if args.rnnType == \"LSTM\":\n",
        "                    stateHidden = stateHidden.detach()\n",
        "                    stateCurrent = stateCurrent.detach()\n",
        "                else:\n",
        "                    stateHidden = stateHidden.data\n",
        "\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                currLoss = loss.item()\n",
        "                \n",
        "                # Only save models with smallest loss per epoch.\n",
        "                if currLoss < bestLoss:\n",
        "                    bestLoss = currLoss\n",
        "                    torch.save(model.state_dict(), f'{args.workingDir}/checkpoints/{args.rnnType}-{args.inputFile}-epoch_{epoch}.pth')\n",
        "            print(f\"Epoch ID: {epoch}, 'the best loss': {bestLoss}\")\n",
        " \n",
        "\n",
        "    # We are ready to train our RNN model!\n",
        "    train(dataset, model, args)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "MPtKKyvUUtBi",
        "outputId": "7004dab9-46a1-4694-e0b4-536c37c88f31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "currently using:  cuda:0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-b0eb494484fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLoadData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# if you're using GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0;31m# summary(model(), input_size=(128, 63, 11))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    987\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 989\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    990\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m     def register_backward_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNNBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;31m# Resets _flat_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    662\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    985\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    986\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 987\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def textGenerator(dataset, idx, model, workingDir, seedSequence, checkpointFileName, outputSize):\n",
        "      checkpointFile = f\"{workingDir}/checkpoints/{checkpointFileName}\"\n",
        "      print (f\"Loading checkpoints from {checkpointFile}.pth \\n\")\n",
        "\n",
        "      # If using GPU, we need the following line.\n",
        "      model.to(device)\n",
        "\n",
        "      # Loading the selected checkpoint (= RNN's weights)\n",
        "      model.load_state_dict(torch.load(f\"{checkpointFile}.pth\"))\n",
        "      model.eval()\n",
        "\n",
        "      # Initialization.\n",
        "      stateHidden, stateCurrent = model.initState(len(seedSequence))\n",
        "\n",
        "      stateHidden = stateHidden[:,0:1,:]\n",
        "      stateCurrent = stateCurrent[:,0:1,:]\n",
        "\n",
        "      # If using GPU, we need the following line.\n",
        "      stateHidden = stateHidden.to(device)\n",
        "\n",
        "      #######################################################################\n",
        "      # *** Task 3 *** The line below is only for LSTM\n",
        "      stateCurrent = stateCurrent.to(device)  # comment this line for GRU\n",
        "      #######################################################################\n",
        "\n",
        "      for i in range(outputSize):\n",
        "          X = torch.tensor([[[w] for w in seedSequence[i:]]])\n",
        "\n",
        "          # If using GPU, we need the following line.\n",
        "          X = X.to(device)\n",
        "\n",
        "          #######################################################################\n",
        "          # *** Task 1 *** Implement states update in our RNN models (as you did above already).\n",
        "          if args.rnnType == \"LSTM\":\n",
        "              # y_pred, (???,???) = model(X, (???,???))\n",
        "              y_pred, (stateHidden, stateCurrent) = model(X, (stateHidden, stateCurrent))\n",
        "          else: # i.e., GRU\n",
        "              # y_pred, ??? = model(X, ???)\n",
        "              y_pred, stateHidden = model(X, stateHidden)\n",
        "          print(y_pred)\n",
        "          outputLogit = y_pred[0][-1]\n",
        "          # Note that, even if you are using GPU, numpy can only be run on \n",
        "          # CPU, so if you are using GPU, please remember to send outputLogit to CPU.\n",
        "          # outputLogit = outputLogit.cpu()\n",
        "          # p = torch.nn.functional.softmax(outputLogit, dim=0).detach().numpy()\n",
        "\n",
        "          # # Below we take the most probable word as our output. \n",
        "          # # Note that \"p\" is provided to \"np.random.choice\" so this numpy function will take softmax scores into account when sampling the output\n",
        "          # # Look at https://numpy.org/doc/stable/reference/random/generated/numpy.random.choice.html\n",
        "          # # to better understand this construction \n",
        "          # wordIndex = np.random.choice(len(outputLogit), p=p)\n",
        "\n",
        "          # Output next word:\n",
        "          outputWord = outputLogit.item()\n",
        "          # print(\"on3\")\n",
        "          print(\"___________\")\n",
        "          print(outputWord)\n",
        "          idx += 1\n",
        "          print(dataset.output_sequence[idx])\n",
        "          print()\n",
        "          # print(outputWord.size())\n",
        "          # sys.stdout.write(outputWord)\n",
        "          # print(\"two\")\n",
        "\n",
        "          # Making sure that each line has \"words_per_line\" words:\n",
        "          words_per_line = 20\n",
        "          if i%words_per_line == 0:\n",
        "              sys.stdout.write(\"\\n\")\n",
        "          else:\n",
        "              sys.stdout.write(\" \")\n",
        "\n",
        "          seedSequence.append(outputWord) "
      ],
      "metadata": {
        "id": "spwtgZI7eToq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# First, we need to define seed sequence for text generation.\n",
        "# The model will generates texts starting with a sequence of words that the model has seen before, \n",
        "# i.e., in the training stage.\n",
        "seed = np.random.choice(len(dataset.intput_sequence)-1)\n",
        "seedSequence = dataset.intput_sequence[seed:seed+args.seqLength]\n",
        "for idx in range(len(seedSequence)):\n",
        "  seedSequence[idx] = seedSequence[idx][0]\n",
        "print(f\"Seed: {seedSequence}\\n\")\n",
        "\n",
        "# Select the model you want to use:\n",
        "args.rnnType = 'LSTM'\n",
        "\n",
        "# And the number of epochs it was trained for (double check you have this checkpoint\n",
        "# in your Google Drive). Usually you should select the checkpoint with the model offering \n",
        "# the smallest loss. But you can also switch between checkpoints to see if there is any obvious\n",
        "# difference in the generated texts between models offering high and low loss values.\n",
        "training_epochs = 30\n",
        "\n",
        "# How many words to generate?\n",
        "outputSize = 1\n",
        "\n",
        "print (\"!!!!!!! Text generation Starts !!!!!!!\\n\")\n",
        "textGenerator(dataset, seed+args.seqLength , model, args.workingDir, seedSequence, \n",
        "    f\"{args.rnnType}-{args.inputFile}-epoch_{training_epochs}\", outputSize=outputSize)\n",
        "print (\"\\n \\n!!!!!!! Text generation Ends !!!!!!!\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1ITUgTu37al",
        "outputId": "77dc65be-33e5-40f1-cbc2-20bdf42dae92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed: [2854.02, 2856.06, 2836.7, 2832.41, 2830.03, 2790.25, 2786.94, 2766.15, 2751.53, 2762.64, 2818.09, 2828.51, 2852.87, 2885.83, 2903.27, 2882.73, 2886.24, 2886.82, 2889.75, 2906.71, 2920.55, 2949.6, 2952.71, 2951.42, 2945.78, 2926.07, 2919.66, 2932.94, 2971.41, 2964.66, 2978.08, 2984.25, 2979.77, 2965.52, 2989.3, 2999.62, 3003.36, 3017.8, 3012.13, 3005.1, 2978.87, 3004.26, 2981.93, 2994.74, 2998.77, 3016.26, 3013.25, 3024.47, 3007.66, 3016.22, 2980.32, 2943.9, 2898.07, 2861.18, 2858.65, 2896.21, 2930.51, 2907.07, 2880.72, 2894.15, 2846.2, 2864.74, 2913.48]\n",
            "\n",
            "!!!!!!! Text generation Starts !!!!!!!\n",
            "\n",
            "Loading checkpoints from /content/gdrive/My Drive/Neural Networks Project//checkpoints/LSTM-input_data-epoch_30.pth \n",
            "\n",
            "tensor([[[-0.0291],\n",
            "         [-0.0469],\n",
            "         [-0.0496],\n",
            "         [-0.0500],\n",
            "         [-0.0501],\n",
            "         [-0.0501],\n",
            "         [-0.0501],\n",
            "         [-0.0501],\n",
            "         [-0.0501],\n",
            "         [-0.0501],\n",
            "         [-0.0501],\n",
            "         [-0.0501],\n",
            "         [-0.0501],\n",
            "         [-0.0501],\n",
            "         [-0.0501],\n",
            "         [-0.0501],\n",
            "         [-0.0501],\n",
            "         [-0.0501],\n",
            "         [-0.0501],\n",
            "         [-0.0501],\n",
            "         [-0.0501],\n",
            "         [-0.0501],\n",
            "         [-0.0501],\n",
            "         [-0.0501],\n",
            "         [-0.0501],\n",
            "         [-0.0501],\n",
            "         [-0.0501],\n",
            "         [-0.0501],\n",
            "         [-0.0501],\n",
            "         [-0.0501],\n",
            "         [-0.0501],\n",
            "         [-0.0501],\n",
            "         [-0.0501],\n",
            "         [-0.0501],\n",
            "         [-0.0501],\n",
            "         [-0.0501],\n",
            "         [-0.0501],\n",
            "         [-0.0501],\n",
            "         [-0.0501],\n",
            "         [-0.0501],\n",
            "         [-0.0501],\n",
            "         [-0.0501],\n",
            "         [-0.0501],\n",
            "         [-0.0501],\n",
            "         [-0.0501],\n",
            "         [-0.0501],\n",
            "         [-0.0501],\n",
            "         [-0.0501],\n",
            "         [-0.0501],\n",
            "         [-0.0501],\n",
            "         [-0.0501],\n",
            "         [-0.0501],\n",
            "         [-0.0501],\n",
            "         [-0.0501],\n",
            "         [-0.0501],\n",
            "         [-0.0501],\n",
            "         [-0.0501],\n",
            "         [-0.0501],\n",
            "         [-0.0501],\n",
            "         [-0.0501],\n",
            "         [-0.0501],\n",
            "         [-0.0501],\n",
            "         [-0.0501]]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "___________\n",
            "-0.05007258802652359\n",
            "[0.029561539198642083]\n",
            "\n",
            "\n",
            "\n",
            " \n",
            "!!!!!!! Text generation Ends !!!!!!!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "GRSpTVU1EF89"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}